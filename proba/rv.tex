
\documentclass{beamer}

%\usepackage{listings}
%\usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage{MyriadPro}
\usepackage{cabin}
\usepackage{graphicx}
\usepackage{array}
\usepackage{tikz}
\usetikzlibrary{positioning, backgrounds, shapes, chains, decorations.pathmorphing}
\usepackage{amsmath,amsthm,amssymb}  
\usepackage{stmaryrd}
%\usepackage{mdsymbol}
\usepackage{MnSymbol}
\usepackage{xcolor}
\usepackage{verbatim}
\usepackage{array}
%\usepackage{csquotes}



\usepackage[absolute,overlay]{textpos}
%\usepackage[texcoord,
%grid,gridcolor=red!10,subgridcolor=green!10,gridunit=pt]
%{eso-pic}



\useoutertheme{infolines}

\newcommand{\hidden}[1]{}

%colors
\definecolor{darkgreen}{rgb}{0,0.5,0}
\usebeamercolor{block title}
\definecolor{beamerblue}{named}{fg}
\usebeamercolor{alert block title}
\definecolor{beamealert}{named}{fg}

\renewcommand{\colon}{\!:\!}


\newcommand\paraitem{%
 \quad
 \makebox[\labelwidth][r]{%
 \makelabel{%
 \usebeamertemplate{itemize \beameritemnestingprefix item}}}\hskip\labelsep}

\newcommand{\mmid}{\mathbin{{\mid}{\mid}}}

\begin{document}

\title{Real-valued Random Variables.} 
\author{Antoine Venant}
%\institute{UDS COLI}
\date{\today}
\maketitle

\begin{frame}
  \frametitle{Motivation.}

  \begin{exampleblock}{Choosing a sample space.}
    Probability of getting $6$ after throwing one fair die: which sample space/event do we use?
    \begin{itemize}
    \item $\Omega_c = \{1,2,3,4,5,6\}$, $e = \{6\}$.
    \item $\Omega_l = \{a,b,c,d,e,f\}$, $e = \{f\}$.
    \item $\Omega = \{\langle 1,1 \rangle, \langle 1,2 \rangle \dots \langle 1,6 \rangle, \langle 2,1 \rangle \dots \langle 6,6 \rangle\}$, $e = \{\langle 6,1 \rangle, \langle 6,2 \rangle, \langle 6,3 \rangle, \langle 6,4 \rangle, \langle 6,5 \rangle, \langle 6,6 \rangle \}$.
    \item Same $\Omega$ but $e = \{\langle 1,6 \rangle, \langle 2,6 \rangle, \langle 3,6 \rangle, \langle 4,6 \rangle, \langle 5,6 \rangle,\langle 6,6 \rangle\}$.
    \end{itemize}
    Under equiprobability: $p(e) = \frac{1}{6}$ regardless of the choice.
  \end{exampleblock}
\end{frame}

\begin{frame}{Abstracting away from specific spaces.}
  \begin{itemize}
  \item Formally capture the properties that we need and that different spaces might exhibit.
  \item Proove more general statements.
  \item From \emph{In this specific space it holds that...} $\rightarrow$ to \emph{In any space \emph{having the right property} it holds that...}.
  \item Two concepts: \emph{Random Variable} and \emph{Probability distribution}.
  \end{itemize}
\end{frame}

\begin{frame}{Random Variable.}
  \begin{block}{Definition}
    Let $\langle \Omega, p \rangle$ be a probability space. A random variable $X: \Omega \mapsto \chi$ is a function from $\Omega$ into some set $\chi$. 
  \end{block}
\end{frame}


\begin{frame}{Examples}
  \begin{exampleblock}{Random Variables over two dice.}
    \[\Omega = \{\langle 1,1 \rangle, \langle 1,2 \rangle \dots \langle 1,6 \rangle, \langle 2,1 \rangle \dots \langle 6,6 \rangle\}\]
    \begin{itemize}
    \item $X_1: \Omega \mapsto \mathbb{R}$, $X_1(\langle x,y\rangle) = x$ (first die outcome).
    \item $X_2: \Omega \mapsto \mathbb{R}$, $X_2(\langle x,y \rangle) = y$ (second die outcome).
    \item $X_3: \Omega \mapsto \mathbb{R}$, $X_3(\langle x,y \rangle) = x + y = X_1(\langle x,y\rangle) + X_2(\langle x,y \rangle)$ (sum of the two dice).
    \end{itemize}
  \end{exampleblock}

  \begin{block}{Remark}
    Recall that (in this course)  $\Omega$ is at most countable. Then so is $X(\Omega) \subseteq \chi$, even when $\chi$ itself is not. \emph{e.g.,} $X_1(\Omega) = \{1,2,3,4,5,6\}$.
  \end{block}
  
\end{frame}

\begin{frame}{Distribution of a random variable.}
  \begin{block}{Definition.}
    Let $\langle \Omega, p \rangle$ be a probability space. And $X: \Omega \mapsto \chi$ be a random variable. The \emph{distribution} of $X$ is the probability measure $p_X$ over $\Lambda = X(\Omega)$ defined as:
    \[\forall \lambda \subseteq \Lambda,  p_X(\lambda) = p(X^{-1}(\lambda)) = p(\{\omega \in \Omega \mid X(\omega) \in \lambda\})\]
  \end{block}

  \begin{block}{Remark.}
    \begin{itemize}
    \item    If $\lambda = \{x_1, \dots, x_, \dots \}$, and $e_1 = f^{-1}(x_1), \dots, e_n = f^{-1}(x_n)$ then
      \[p_X(\lambda) = p(e_1 \cup \dots \cup e_n \cup \dots).\]
    \item $p(X \in \lambda)$ is syntactic sugar for  $p_X(\lambda)$.
    \item $p(X = x)$ is syntactic sugar for $p(X \in \{x\})$
    \end{itemize}
  \end{block} 
\end{frame}

\begin{frame}{Examples}
  \begin{exampleblock}{Random Variables over two dice.}
    \[\Omega = \{\langle 1,1 \rangle, \langle 1,2 \rangle \dots \langle 1,6 \rangle, \langle 2,1 \rangle \dots \langle 6,6 \rangle\}\]
    \begin{itemize}
    \item $X_1: \Omega \mapsto \mathbb{R}$, $X_1(\langle x,y \rangle) = x$ (first die outcome).
    \item $X_2: \Omega \mapsto \mathbb{R}$, $X_2(\langle x,y \rangle) = y$ (second die outcome).
    \item $X_3: \Omega \mapsto \mathbb{R}$, $X_3 = X_1 + X_2$ (sum of the two dice).
    \end{itemize}
  \end{exampleblock}

  \begin{itemize}
  \item $X_1$ and $X_2$ have same distribution: $p(X_1 = 1) = p(X_2 = 1) = \frac{1}{6}$.
  \item $p(X_3 = k) = \sum^{k}_{i=1} p(X_1 = i)p(X_2 = k - i)$. 
  \end{itemize}  
\end{frame}

\begin{frame}
  \frametitle{Some important distributions.}

  \begin{exampleblock}{Uniform distribution.}
    Measure over finite set $\{x_1, \dots, x_n\}$ corresponding to the distribution of a random variable $X$ s.t. $p(X = x_i) = \frac{1}{n}$. \emph{e.g.}, a fair $6-sided$ die is represented by the uniform distribution over \{1,2,3,4,5,6\}.
  \end{exampleblock}

  \begin{exampleblock}{Bernouilli distribution of parameter $p_0$.}
    Throwing a biased coin, associating $1$ with tail and $0$ with head: distribution of a r.v. into $\{0, 1\}$ such that $p(X = 0) = p_0, p(X = 1) = 1 - p_0$.
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Some important distributions.}
  \begin{exampleblock}{Hypergeometric distribution.}
    Box containing $N$ balls. $m$ are red. One draws $n$ balls without replacement. $X = k$: $k$ red balls drawn.
    \[
    p(X = k) = \frac{C^k_mC^{n-k}_{N-m}}{C^n_N}
    \]
  
  \end{exampleblock}

  \begin{exampleblock}{Binomial distribution.}
    Same experiment, but with replacement between draws.
    \[
    p(X = k) = C^k_nq^{k}(1 - q)^{n-k}.
    \]
    Where $q = \frac{m}{N}$.
  \end{exampleblock}
\end{frame}

\begin{frame}{Derivation of the binomial distribution.}
  Box containing $N$ balls. $m$ are red. One draws $n$ balls \textbf{with replacement}. $X = k$: $k$ red balls drawn.
  
  \begin{itemize}
  \item Consider the event $e_0$: `drawing $k$ red balls first, then $n-k$ blue balls'
  \item Probability of drawing the $i^{th}$ ball red is $\frac{m}{N}$.
  \item So $p(e_0) = (\frac{m}{N})^k(1-\frac{m}{N})^{n-k}$.
  \item Let $p_1, \dots, p_k \in [1,n]$, pairwise distinct.
  \item Consider now $e_{p_1, \dots, p_k}$: `The $p_1^{th}$ ball drawn is red and the $p_2^{th}$ ball drawn is red and ... and the $p_k^{th}$ ball drawn is red, and all the others are not red'.
  \item Since the drawing are independent, the value of $p_1, \dots, p_k$ does not matter, and $p(e_{p_1, \dots, p_k}) = p(e_{1, 2, \dots, k}) = p(e_0)$.
  \item There are $C^k_n$ possible choices for $p_1, \dots, p_k$ under considered assumptions $\{p_1, \dots, p_k\} \subseteq [1,n]$ with $|\{p_1, \dots, p_k\}| = k$.
  \item So we have \[p(X = k) = \sum_{\{p_1, \dots, p_k\} \subseteq [1,n] \textnormal{ pairwise distinct} } p(e_{p_1, \dots, p_k}) =  C^k_n (\frac{m}{N})^k(1-\frac{m}{N})^{n-k}.\]
  \end{itemize}
  
\end{frame}



\begin{frame}{Some important distributions.}
  \begin{exampleblock}{Geometric distribution.}
    One repeats independent bernouilli trials until one gets $0$. $X$ is number of repeated trials. For $k \in \mathbb{N}^*$
    \[p(X = k) = (1 - p_0)^{k-1}p_0\]
    
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Constructing new random variables.}
  \begin{block}{Composition.}
    For any random variable $X: \Omega \mapsto A$ and function $f: A \mapsto B$, $Y = f \circ X$ is also a random variable (with values in $B$)!
    \[Y(\omega) = (f \circ X) (\omega) = f(X(\omega)) \in B\]
    For simplicity, write $f(X)$ instead of $f \circ X$. 
  \end{block}
  \begin{exampleblock}{Examples.}
    \begin{itemize}
    \item $X^2$ obtained for $X: \Omega \mapsto \mathbb{R}$, $f: \left \{ \begin{array}{l} \mathbb{R} \mapsto \mathbb{R}\\ x \mapsto x^2 \end{array} \right .$.
    \item $aX$ obtained for $X: \Omega \mapsto \mathbb{R}$, $a \in \mathbb{R}$, $f(x) = a x$. $f(X)$.
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Constructing new random variables.}
  \begin{block}{More generally:}
    If $X_1 : \Omega \mapsto A_1, \dots, X_n: \mapsto A_n$ are all random variables over the same space $\Omega$, and $\phi: A_1 \times \dots \times A_n \mapsto B$ then $\phi(X_1, \dots, X_n)$ is a random variable with values in $B$
    \[\phi(X_1, \dots, X_n)(\omega) = \phi(X_1(\omega), \dots, X_n(\omega)).\]
  \end{block}

  \begin{exampleblock}{Example}
     $X + Y$ obtained for $X, Y: \Omega \mapsto \mathbb{R}$, $\phi: (x,y) \mapsto x + y$.
  \end{exampleblock}
  
  
\end{frame}

\begin{frame}{Expectation.}
  We now consider only real valued random variables (\emph{i.e.} applications $X: \Omega \mapsto \mathbb{R}$).

  \begin{itemize}
  \item We're assigning numbers to random outcomes.
  \item Mean we can think about things like `average' outcome.
  \item \emph{e.g.} if we throw a die multiple time and average the results, we get $3.5$.
  \item $3.5$ is the \emph{expectation} of a random variable with uniform distribution over $\{1,2,3,4,5,6\}$.
  \item We will define a mathematical quantity and (next time) show that it fits this intuition.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Expectation}
  \begin{block}{Definition}
    Let $\langle \Omega, p \rangle$ be a probability space. Let $X \Omega \mapsto \mathbb{R}$ be a real-valued random variable, and let $\Lambda = X(\Omega) = \{x_1, \dots x_n, \dots\}$. The expectation of $X$ is defined if and only if:
    \[\begin{aligned} &X \ge 0\\\textnormal{or }&\sum^{\infty}_{i=1} p(X = x_i) \times |x_i| < \infty.\end{aligned}\]
    When this condition is fulfilled, it is defined as:
    \[\mathbb{E}(X) = \sum^{\infty}_{i=1} p(X = x_i) \times x_i = \sum_{\omega \in \Omega} p(\omega) X_i(\omega) .\]
  \end{block}
  \begin{itemize}
  \item \alert{Always defined when $X(\Omega)$ is finite.}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example}
  \begin{exampleblock}{Uniform distribution.}
    \begin{itemize}
    \item $X$ has a uniform distribution over $\{1, \dots, n\}$.
    \item $X$ has an expectation (finite sum $< \infty$)
    \item $\mathbb{E}(X) = \sum^n_{i=1} \frac{1}{n} \times i = \frac{1}{n} \times \sum^n_{i = 1} i = \frac{n+1}{2}$.     
    \item For the $6$-sided fair die: $\frac{6+1}{2} = 3.5$.
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Example}
  \begin{exampleblock}{Binomial distribution.}
    \begin{itemize}
    \item $X \in [1,n]$, $p(X = k) = C^k_n q^k(1-q)^{n-k}$.
    \item $\mathbb{E}(X) = nq$.
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Properties:}
  \begin{block}{Linearity.}
    If $X$ and $Y$ have an expectation and it is not the case that $\{\mathbb{E}(X), \mathbb{E}(Y)\} = \{\infty, {-}\infty\}$,
    \[ \mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y). \]
    For any $a \in \mathbb{R}$
    \[\mathbb{E}(aX) = a\mathbb{E}(X).\]
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Properties.}
  \begin{itemize}
  \item $p(X \in \lambda) = \mathbb{E}(1_{\lambda})$.
  \item $X$ and $Y$ have the same distribution iff for any function $f: \mathbb{R} \rightarrow \mathbb{R}$, $\mathbb{E}(f \circ X) = \mathbb{E}(f \circ Y)$.
  \end{itemize}

  \begin{block}{Markov Inequality}
      For $X: \Omega \mapsto \mathbb{R}^{+}$ a {\bf positive} random variable, and $a \in \mathbb{R}^{+}$ {\bf positive} scalar,
      \[P(X \ge a) \le \frac{1}{a}\mathbb{E}(X).\]
  \end{block}
  
\end{frame}

\begin{frame}{Example}
  \begin{exampleblock}{Random Variables over two dice.}
    \[\Omega = \{\langle 1,1 \rangle, \langle 1,2 \rangle \dots \langle 1,6 \rangle, \langle 2,1 \rangle \dots \langle 6,6 \rangle\}\]
    \begin{itemize}
    \item $X_3: \Omega \mapsto \mathbb{R}$, $X_3 = X_1 + X_2$ (sum of the two dice).
    \item $\mathbb{E}(X_3) = 7$.
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Variance}
  \begin{itemize}
  \item Idea behind expectation: `average' outcome.
  \item But same `average' can be achieved in different ways.
  \item Measure the `tendency to deviate from average result' of an experiment.
  \end{itemize}

  \begin{exampleblock}{Two experiment}
    \begin{itemize}
    \item $p(X = 12) = 1/2$ and $p(X=-8) = 1/2$.
    \item $\forall i \in \mathbb{N}^{*}$ $p(X = i)=\frac{1}{2^{i+1}}$.
    \item Same expectation, different deviations.
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Variance}
  \begin{block}{Definition}
    Let $X: \Omega \rightarrow \mathbb{R}$ be such that $\mathbb{E}(X^2)$ exists and $\mathbb{E}(X^2) < \infty$.
    \begin{itemize}
    \item Then $\mathbb(E)(X)$ exists and $E(X) \in \mathbb{R}$ (follows from Cauchy-Schwartz inequality in linear algebra).
    \item So... $(X - \mathbb{E}(X))^2$ is a random variable.
    \end{itemize}
    \[Var(X) = \mathbb{E}((X - \mathbb{E}(X))^2)\]
  \end{block}
  \begin{itemize}
  \item Variance is always positive.
  \item $\sigma(X) = \sqrt(Var(X))$ is called the \textbf{standard deviation}.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example}
  \begin{exampleblock}{Two experiment}
      \begin{itemize}
        \item $p(X = 12) = 1/2$ and $p(X=-8) = 1/2$. \alert{$V(X) = 100 = 10^2$}
        \item $\forall i \in \mathbb{N}^{*}$ $p(X = i)=\frac{1}{2^{i+1}}$. \alert{$V(X) = 2 = \sqrt(2)^2$}
      \end{itemize}
    \end{exampleblock}
\end{frame}


\begin{frame}
  \frametitle{Properties}
  \begin{itemize}
  \item $var(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2$.
  \item for $a, b \in \mathbb{R}$, $var(aX + b) = a^2var(X)$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Bienaym\'e-Chebyshev inequality}
  If $X$ is a real-valued random variable such that $\mathbb{E}(X^2$ exists and is finite, if $a \in \mathbb{R}$ and $a \ge 0$ then
  \[p(|X - \mathbb{E}(X)| \ge a) \le \frac{var(X)}{a^2}.\]
\end{frame}

\begin{frame}
  \frametitle{Conditioning on a random variable's outcome.}
  \begin{itemize}
  \item $p(X \in \lambda) = p(X^{-1}(\lambda))$.
  \item For simplicity, we refer to `the distribution of a random variable $X: \Omega \rightarrow \chi$.
  \item But depends on the probability $p$ on $\Omega$: for the same def. of $X$, different distributions w.r.t. $\langle \Omega, p \rangle$ and $\langle \Omega, p' \rangle$.
  \item So when disambiguation is needed, we say distribution of $X$ \textbf{with respect to} proability measure $p$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Conditional Probability.}

  \begin{block}{Definition.}
    Let $\langle \Omega, p \rangle$ be a probability space. Let $X: \Omega \rightarrow \chi$ and $Y: \Omega \rightarrow \chi'$ be two random variables over $\Omega$. Let $\lambda \subseteq \chi$ be such that $p(X \in \lambda) \neq 0$.
    The conditional distribution of $Y$ knowing $X \in \lambda$ is the distribution of $Y$ w.r.t. $p( \cdot \mid X^{-1}(\lambda))$, \emph{i.e.}
    \[p(Y \in \gamma \mid X \in \lambda) = p(Y^{-1}(\gamma) \mid X^{-1}(\lambda)) = \frac{p(Y^{-1}(\gamma) \cap X^{-1}(\lambda))}{p(X^{-1}(\lambda))}.\]
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Joint probability.}
  Let $\langle \Omega, p \rangle$ be a probability space. Let $X: \Omega \rightarrow \chi$ and $Y: \Omega \rightarrow \chi'$ be two random variables over $\Omega$.
  \[Z: \begin{array}{l} \Omega \mapsto \chi \times \chi'\\\omega \mapsto \langle X(\omega), Y(\omega) \rangle \end{array}\] is a random variable with values in $\chi \times \chi'$. It is called a \emph{random vector} (of length $2$). The distribution of $Z$ is called the \emph{joint probability} of $X$ and $Y$. The distribution of $X$ and $Y$ are called the \emph{marginal} distributions of $Z$.

  \begin{itemize}
  \item Analoguous definitions for $ > 2$ random variables.
  \end{itemize}
\end{frame}

\begin{frame}{Properties of random vectors.}
  \[Z: \begin{array}{l} \Omega \mapsto \chi \times \chi'\\\omega \mapsto \langle X(\omega), Y(\omega) \rangle \end{array}\]
  \begin{itemize}
  \item $p(X \in \lambda, Y \in \gamma)$ is defined as $p(Z \in \lambda \times \gamma)$.
  \item $p(X \in \lambda) = p(X \in \lambda, Y \in \chi') = \sum_{y \in \chi'} p(X \in \lambda, Y = y)$.
  \item $p(Y \in \gamma) = p(X \in \chi, Y \in \gamma) = \sum_{x \in \chi} p(X=x, Y \in \gamma)$
  \item $p(X \in \lambda, Y \in \gamma) = p(Y \in \gamma) \times p(X \in \lambda \mid Y \in \gamma)$.
  \end{itemize}
  
\end{frame}

\begin{frame}\frametitle{Independent random variable.}
  $n$ random variables over the same space $X_1 : \Omega \mapsto A_1, \dots, X_n: \mapsto A_n$ are \emph{mutually independent} iff for any sequence $\alpha_1 \subseteq A_1, \dots, \alpha_n \subseteq A_n$
  \[ p(X_1 \in A_1,\dots, X_n \in A_n) = \prod^n_{i=1}p(X_i \in A_i).\]
\end{frame}

\begin{frame}{Weak law of large numbers.}
  \begin{block}{Theorem}
    Let $X_1, \dots, X_n \dots$ be an infinite sequence of identically distributed (they all have the same distribution) and independent (variables in any finite subsequence $X_{i_1} \dots X_{i_k}$ mutually independent) real-valued random variable over a probability space $\langle \Omega, p \rangle$. For each $n \in \mathbb{N}$, define $M_n = \frac{1}{n}(X_1 + \dots + X_n)$.

   \[\forall \epsilon > 0\, lim_{n \rightarrow + \infty} p(|M_n - \mathbb{E}(X_1)| > \epsilon ) = 0 .\]
  \end{block}
\end{frame}

\begin{frame}\frametitle{Strong law of large numbers.}
  A more powerful statement is also true:
  \[ p(\{\omega \in \Omega \mid lim_{n \rightarrow \infty} M_n(\omega) \neq \mathbb{E}(X_1) \}) = 0 .\]
\end{frame}

\begin{frame}{Meaning.}
  \begin{itemize}
  \item $M_N: $ average outcome of random experiment $X$ over $n$ repeated trials.
  \item For large $n$, this average will approach the mathematical expectation!
  \item Justifies our abstract definition of an expectation.
  \end{itemize}
\end{frame}

\begin{frame}{The frequentist interpretation.}
  \begin{exampleblock}{A special case.}
    \begin{itemize}
    \item $Z_1, \dots, Z_n, \dots$ identically distributed and independent.
    \item $\mathcal{Z}$ the common target space ($\forall i \in \mathbb{N}\,Z_i : \Omega \rightarrow \mathcal{Z}$).
    \item For $z \in \mathcal{Z}$, consider random variables $X_i = 1_{Z_i = x}$:
      \begin{itemize}
      \item $X_i(\omega) = 1$ if $Z_i(\omega) = z$, $X_i(\Omega) = 0$ otherwise.
      \end{itemize}
    \item $E(X_1) = p(Z_1 = x)$.
    \item $M_N = \frac{1}{n}(X_1 + \dots + X_n)$: frequency of outcome $z$ over repeated trials.
    \item \textbf{Law of large numbers: frequency of occurence of $z$ goes toward $p(X_1 = z)$.}
    \item \emph{frequentist interpretation} as a theorem.
    \end{itemize}
    \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{However...}
  \begin{itemize}
  \item<2-> Some limitations in our definitions: $\Omega$ at most countable.
  \item<3-> Does there actually exists an $\Omega$ with $X_1, \dots, X_n, \dots$ i.i.d.?
  \item<4-> Unfortunately in general not a countable one...
  \item<5-> But with a lot of care, definitions can be conservatively extended to continuous case (measure theory).
  \end{itemize}  
\end{frame}


\end{document}
